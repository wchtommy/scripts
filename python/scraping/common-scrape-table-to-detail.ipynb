{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query method to get the detail page of a table row\n",
    "# Return response data from get request\n",
    "def get_table(index):\n",
    "    # Modify HERE\n",
    "    page_size = 20\n",
    "    base_url = \"https://www.edr.hk/ajax/search-all?draw=6&columns%5B0%5D%5Bdata%5D=&columns%5B0%5D%5Bname%5D=&columns%5B0%5D%5Bsearchable%5D=true&columns%5B0%5D%5Borderable%5D=false&columns%5B0%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B0%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B1%5D%5Bdata%5D=&columns%5B1%5D%5Bname%5D=&columns%5B1%5D%5Bsearchable%5D=true&columns%5B1%5D%5Borderable%5D=false&columns%5B1%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B1%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B2%5D%5Bdata%5D=&columns%5B2%5D%5Bname%5D=&columns%5B2%5D%5Bsearchable%5D=true&columns%5B2%5D%5Borderable%5D=false&columns%5B2%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B2%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B3%5D%5Bdata%5D=&columns%5B3%5D%5Bname%5D=&columns%5B3%5D%5Bsearchable%5D=true&columns%5B3%5D%5Borderable%5D=false&columns%5B3%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B3%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B4%5D%5Bdata%5D=&columns%5B4%5D%5Bname%5D=&columns%5B4%5D%5Bsearchable%5D=true&columns%5B4%5D%5Borderable%5D=false&columns%5B4%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B4%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B5%5D%5Bdata%5D=address_chi&columns%5B5%5D%5Bname%5D=&columns%5B5%5D%5Bsearchable%5D=true&columns%5B5%5D%5Borderable%5D=false&columns%5B5%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B5%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B6%5D%5Bdata%5D=district&columns%5B6%5D%5Bname%5D=&columns%5B6%5D%5Bsearchable%5D=true&columns%5B6%5D%5Borderable%5D=false&columns%5B6%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B6%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B7%5D%5Bdata%5D=phone&columns%5B7%5D%5Bname%5D=&columns%5B7%5D%5Bsearchable%5D=true&columns%5B7%5D%5Borderable%5D=false&columns%5B7%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B7%5D%5Bsearch%5D%5Bregex%5D=false&search%5Bvalue%5D=&search%5Bregex%5D=false&_=1679641375878\"\n",
    "    url_variance = \"&start=%s&length=%s\" % (index * page_size, page_size)\n",
    "    res = requests.get(base_url + url_variance)\n",
    "    return res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return True to stop scraping\n",
    "def get_table_end_condition(index, data):\n",
    "    # Modify HERE\n",
    "    return len(data['data']) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_detail(index, data, html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Extract doctor name\n",
    "    name_element = soup.find('h1')\n",
    "    doctor_name = name_element.text.strip()\n",
    "\n",
    "    # Extract clinic address\n",
    "    address_element = soup.find('div', {'class': 'profile-box-general'})\n",
    "    clinic_address = address_element.find_all('p')[0].text.strip()\n",
    "\n",
    "    # Extract phone number\n",
    "    phone_element = soup.find('h2', text='診症電話')\n",
    "    if phone_element is not None:\n",
    "        phone_number = phone_element.find_next('p').text.strip()\n",
    "\n",
    "    # Extract medical services offered\n",
    "    services_element = soup.find('h2', text='醫療服務包括')\n",
    "    if services_element is not None:\n",
    "        services_list = services_element.find_next('ul')\n",
    "        medical_services = [service.text.strip() for service in services_list.find_all('li')]\n",
    "\n",
    "    # Extract other information\n",
    "    other_info_element = soup.find('div', {'class': 'other-info'})\n",
    "    if other_info_element is not None:\n",
    "        other_info = [p.text.strip() for p in other_info_element.find_all('p')]\n",
    "\n",
    "    # Extract professional qualifications\n",
    "    profile_cert_list = soup.find('ul', class_='profile-cert-list')\n",
    "    certifications = profile_cert_list.find_all('li')\n",
    "    if certifications is not None:\n",
    "        professional_qualifications = [cert.text.strip() for cert in certifications]\n",
    "\n",
    "    return {\n",
    "        '中文姓名': data['name_chi'] if 'name_chi' in data else None,\n",
    "        '英文姓名': data['name_eng'] if 'name_eng' in data else None,\n",
    "        '姓別': data['gender'],\n",
    "        '專科': data['speciality_name_chi'] if 'speciality_name_chi' in data else None,\n",
    "        '電話': data['phone'] if 'phone' in data else None,\n",
    "        '地區': data['district']   if 'district' in data else None,\n",
    "        '地址': data['address_chi'] if 'address_chi' in data else None,\n",
    "        '醫療服務': medical_services if 'medical_services' in locals() else None,\n",
    "        '其他資料': other_info if 'other_info' in locals() else None,\n",
    "        '專業資格': professional_qualifications if 'professional_qualifications' in locals() else None,\n",
    "        '執業': data['practice'] if 'practice' in data else None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detail(index, data, out):\n",
    "    # Modify HERE\n",
    "    for row in data['data']:\n",
    "        base_url = \"https://www.edr.hk/\"\n",
    "        url = base_url + row['url']\n",
    "        res = requests.get(url)\n",
    "        res_data = scrape_detail(index, row, res.text)\n",
    "        \n",
    "        fieldnames = list(res_data.keys())\n",
    "        writer = csv.DictWriter(out, fieldnames=fieldnames)\n",
    "        writer.writerow(res_data)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\wchto\\Desktop\\script-library\\python\\scraping\\common-scrape-table-to-detail.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39moutput.csv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m out:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     main(out)\n",
      "\u001b[1;32mc:\\Users\\wchto\\Desktop\\script-library\\python\\scraping\\common-scrape-table-to-detail.ipynb Cell 6\u001b[0m in \u001b[0;36mmain\u001b[1;34m(out)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m get_table_end_condition(index, res_data):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m get_detail(index, res_data, out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\wchto\\Desktop\\script-library\\python\\scraping\\common-scrape-table-to-detail.ipynb Cell 6\u001b[0m in \u001b[0;36mget_detail\u001b[1;34m(index, data, out)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m url \u001b[39m=\u001b[39m base_url \u001b[39m+\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m res \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m res_data \u001b[39m=\u001b[39m scrape_detail(index, row, res\u001b[39m.\u001b[39;49mtext)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m fieldnames \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(res_data\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m writer \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mDictWriter(out, fieldnames\u001b[39m=\u001b[39mfieldnames)\n",
      "\u001b[1;32mc:\\Users\\wchto\\Desktop\\script-library\\python\\scraping\\common-scrape-table-to-detail.ipynb Cell 6\u001b[0m in \u001b[0;36mscrape_detail\u001b[1;34m(index, data, html)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Extract professional qualifications\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m profile_cert_list \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mul\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mprofile-cert-list\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m certifications \u001b[39m=\u001b[39m profile_cert_list\u001b[39m.\u001b[39;49mfind_all(\u001b[39m'\u001b[39m\u001b[39mli\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mif\u001b[39;00m certifications \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wchto/Desktop/script-library/python/scraping/common-scrape-table-to-detail.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     professional_qualifications \u001b[39m=\u001b[39m [cert\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m cert \u001b[39min\u001b[39;00m certifications]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "def main(out):\n",
    "    spamwriter = csv.writer(out, quoting=csv.QUOTE_MINIMAL)\n",
    "    index = 0\n",
    "    while True:\n",
    "        print(index)\n",
    "        res_data = get_table(index)\n",
    "        if get_table_end_condition(index, res_data):\n",
    "            break\n",
    "        get_detail(index, res_data, out)\n",
    "        index += 1\n",
    "\n",
    "with open('output.csv', 'w', encoding='utf8') as out:\n",
    "    main(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c5b04c1a0bb08e7c699a9c1cb8154540096717a495a844ef16b8ded65696971"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
